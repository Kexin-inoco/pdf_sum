{
  "ai_generated_toc": "```markdown\n# Table of Contents\n\n1. [Introduction](#introduction) (Page 1)  \n2. [Literature Review](#literature-review) (Page 3)  \n   2.1. [Research Funding and Its Impact](#research-funding-and-its-impact) (Page 3)  \n   2.2. [Gender Disparities in Scientific Research](#gender-disparities-in-scientific-research) (Page 3)  \n   2.3. [Geographical Disparities in Research Funding](#geographical-disparities-in-research-funding) (Page 4)  \n   2.4. [Topic Modelling](#topic-modelling) (Page 4)  \n   2.5. [Methodological Approaches to Effect Estimation](#methodological-approaches-to-effect-estimation) (Page 4)  \n3. [Data](#data) (Page 5)  \n4. [Methodology](#methodology) (Page 6)  \n   4.1. [Data Preprocessing](#data-preprocessing) (Page 7)  \n   4.1.1. [Removal of incomplete entries: All entries lacking application summaries were](#removal-of-incomplete-entries) (Page 7)  \n   4.1.2. [Elimination of duplicates: Duplicate records were identified and eliminated to maintain](#elimination-of-duplicates) (Page 7)  \n   4.1.3. [Translation of non-English content: Non-English content, such as French and Italian,](#translation-of-non-english-content) (Page 7)  \n   4.1.4. [Cleaning of non-textual elements: Non-textual elements, including punctuation,](#cleaning-of-non-textual-elements) (Page 7)  \n   4.1.5. [Text normalization: The text was converted to lowercase and tokenized, facilitating](#text-normalization) (Page 7)  \n   4.1.6. [Stop-word removal: Common English stop-words were removed to reduce noise and](#stop-word-removal) (Page 7)  \n   4.1.7. [Exclusion of domain-specific terms: In addition to general stop-words, domain-specific](#exclusion-of-domain-specific-terms) (Page 7)  \n   4.1.8. [Lemmatization: Words were reduced to their root forms by lemmatization, aiding in the](#lemmatization) (Page 7)  \n   4.1.9. [N-grams: Bigrams and trigrams were also considered to capture contextually relevant](#n-grams) (Page 7)  \n   4.2. [Topic Modelling](#topic-modelling-2) (Page 7)  \n   4.3. [Comparative Analysis of Topic Models](#comparative-analysis-of-topic-models) (Page 8)  \n   4.3.1. [Triplet Matches (n=5): Groups consisting of one topic from each model (BERTopic,](#triplet-matches) (Page 8)  \n   4.3.2. [Unique Topics (n=8): Topics from a single model that did not achieve a cosine](#unique-topics) (Page 9)  \n   4.4. [Covariate Effect Estimation](#covariate-effect-estimation) (Page 10)  \n5. [Results](#results) (Page 12)  \n   5.1. [Comparative Analysis of Topic Models](#comparative-analysis-of-topic-models-2) (Page 12)  \n   5.1.1. [BERTopic: Leverages pre-trained transformer models to generate context-aware](#bertopic) (Page 16)  \n   5.1.2. [LDA: As a generative probabilistic model, LDA assumes topics are distributions over](#lda) (Page 17)  \n   5.2. [Covariate Effect Estimation](#covariate-effect-estimation-2) (Page 17)  \n6. [Conclusion](#conclusion) (Page 20)  \n7. [Limitations and Future Work](#limitations-and-future-work) (Page 21)  \n```",
  "extracted_titles": [
    {
      "title": "1. Introduction",
      "page": 1,
      "original_text": "1. Introduction (Page 1)"
    },
    {
      "title": "2. Literature Review",
      "page": 3,
      "original_text": "2. Literature Review (Page 3)"
    },
    {
      "title": "2.1. Research Funding and Its Impact",
      "page": 3,
      "original_text": "2.1. Research Funding and Its Impact (Page 3)"
    },
    {
      "title": "2.2. Gender Disparities in Scientific Research",
      "page": 3,
      "original_text": "2.2. Gender Disparities in Scientific Research (Page 3)"
    },
    {
      "title": "2.3. Geographical Disparities in Research Funding",
      "page": 4,
      "original_text": "2.3. Geographical Disparities in Research Funding (Page 4)"
    },
    {
      "title": "2.4. Topic Modelling",
      "page": 4,
      "original_text": "2.4. Topic Modelling (Page 4)"
    },
    {
      "title": "2.5. Methodological Approaches to Effect Estimation",
      "page": 4,
      "original_text": "2.5. Methodological Approaches to Effect Estimation (Page 4)"
    },
    {
      "title": "3. Data",
      "page": 5,
      "original_text": "3. Data (Page 5)"
    },
    {
      "title": "4. Methodology",
      "page": 6,
      "original_text": "4. Methodology (Page 6)"
    },
    {
      "title": "4.1. Data Preprocessing",
      "page": 7,
      "original_text": "4.1. Data Preprocessing (Page 7)"
    },
    {
      "title": "1. Removal of incomplete entries: All entries lacking application summaries were",
      "page": 7,
      "original_text": "1. Removal of incomplete entries: All entries lacking application summaries were (Page 7)"
    },
    {
      "title": "2.  Elimination of duplicates: Duplicate records were identified and eliminated to maintain",
      "page": 7,
      "original_text": "2.  Elimination of duplicates: Duplicate records were identified and eliminated to maintain (Page 7)"
    },
    {
      "title": "3. Translation of non-English content: Non-English content, such as French and Italian,",
      "page": 7,
      "original_text": "3. Translation of non-English content: Non-English content, such as French and Italian, (Page 7)"
    },
    {
      "title": "4. Cleaning of non-textual elements: Non-textual elements, including punctuation,",
      "page": 7,
      "original_text": "4. Cleaning of non-textual elements: Non-textual elements, including punctuation, (Page 7)"
    },
    {
      "title": "5. Text normalization: The text was converted to lowercase and tokenized, facilitating",
      "page": 7,
      "original_text": "5. Text normalization: The text was converted to lowercase and tokenized, facilitating (Page 7)"
    },
    {
      "title": "6. Stop-word removal: Common English stop-words were removed to reduce noise and",
      "page": 7,
      "original_text": "6. Stop-word removal: Common English stop-words were removed to reduce noise and (Page 7)"
    },
    {
      "title": "7. Exclusion of domain-specific terms: In addition to general stop-words, domain-specific",
      "page": 7,
      "original_text": "7. Exclusion of domain-specific terms: In addition to general stop-words, domain-specific (Page 7)"
    },
    {
      "title": "8. Lemmatization: Words were reduced to their root forms by lemmatization, aiding in the",
      "page": 7,
      "original_text": "8. Lemmatization: Words were reduced to their root forms by lemmatization, aiding in the (Page 7)"
    },
    {
      "title": "9. N-grams: Bigrams and trigrams were also considered to capture contextually relevant",
      "page": 7,
      "original_text": "9. N-grams: Bigrams and trigrams were also considered to capture contextually relevant (Page 7)"
    },
    {
      "title": "4.2. Topic Modelling",
      "page": 7,
      "original_text": "4.2. Topic Modelling (Page 7)"
    },
    {
      "title": "4.3. Comparative Analysis of Topic Models",
      "page": 8,
      "original_text": "4.3. Comparative Analysis of Topic Models (Page 8)"
    },
    {
      "title": "• Triplet Matches (n=5): Groups consisting of one topic from each model (BERTopic,",
      "page": 8,
      "original_text": "• Triplet Matches (n=5): Groups consisting of one topic from each model (BERTopic, (Page 8)"
    },
    {
      "title": "• Unique Topics (n=8): Topics from a single model that did not achieve a cosine",
      "page": 9,
      "original_text": "• Unique Topics (n=8): Topics from a single model that did not achieve a cosine (Page 9)"
    },
    {
      "title": "4.4. Covariate Effect Estimation",
      "page": 10,
      "original_text": "4.4. Covariate Effect Estimation (Page 10)"
    },
    {
      "title": "5. Results",
      "page": 12,
      "original_text": "5. Results (Page 12)"
    },
    {
      "title": "5.1. Comparative Analysis of Topic Models",
      "page": 12,
      "original_text": "5.1. Comparative Analysis of Topic Models (Page 12)"
    },
    {
      "title": "• BERTopic: Leverages pre-trained transformer models to generate context-aware",
      "page": 16,
      "original_text": "• BERTopic: Leverages pre-trained transformer models to generate context-aware (Page 16)"
    },
    {
      "title": "• LDA: As a generative probabilistic model, LDA assumes topics are distributions over",
      "page": 17,
      "original_text": "• LDA: As a generative probabilistic model, LDA assumes topics are distributions over (Page 17)"
    },
    {
      "title": "5.2. Covariate Effect Estimation",
      "page": 17,
      "original_text": "5.2. Covariate Effect Estimation (Page 17)"
    },
    {
      "title": "6. Conclusion",
      "page": 20,
      "original_text": "6. Conclusion (Page 20)"
    },
    {
      "title": "7. Limitations and Future Work",
      "page": 21,
      "original_text": "7. Limitations and Future Work (Page 21)"
    }
  ],
  "metadata": {
    "total_pages": 35,
    "titles_found": 38,
    "model": "gpt-4o-mini",
    "temperature": 0.3,
    "timestamp": "2025-10-22T18:53:23.869065"
  }
}
```markdown
# Table of Contents

1. [Introduction](#introduction) (Page 1)  
2. [Literature Review](#literature-review) (Page 3)  
   2.1. [Research Funding and Its Impact](#research-funding-and-its-impact) (Page 3)  
   2.2. [Gender Disparities in Scientific Research](#gender-disparities-in-scientific-research) (Page 3)  
   2.3. [Geographical Disparities in Research Funding](#geographical-disparities-in-research-funding) (Page 4)  
   2.4. [Topic Modelling](#topic-modelling) (Page 4)  
   2.5. [Methodological Approaches to Effect Estimation](#methodological-approaches-to-effect-estimation) (Page 4)  
3. [Data](#data) (Page 5)  
4. [Methodology](#methodology) (Page 6)  
   4.1. [Data Preprocessing](#data-preprocessing) (Page 7)  
   4.1.1. [Removal of incomplete entries: All entries lacking application summaries were](#removal-of-incomplete-entries) (Page 7)  
   4.1.2. [Elimination of duplicates: Duplicate records were identified and eliminated to maintain](#elimination-of-duplicates) (Page 7)  
   4.1.3. [Translation of non-English content: Non-English content, such as French and Italian,](#translation-of-non-english-content) (Page 7)  
   4.1.4. [Cleaning of non-textual elements: Non-textual elements, including punctuation,](#cleaning-of-non-textual-elements) (Page 7)  
   4.1.5. [Text normalization: The text was converted to lowercase and tokenized, facilitating](#text-normalization) (Page 7)  
   4.1.6. [Stop-word removal: Common English stop-words were removed to reduce noise and](#stop-word-removal) (Page 7)  
   4.1.7. [Exclusion of domain-specific terms: In addition to general stop-words, domain-specific](#exclusion-of-domain-specific-terms) (Page 7)  
   4.1.8. [Lemmatization: Words were reduced to their root forms by lemmatization, aiding in the](#lemmatization) (Page 7)  
   4.1.9. [N-grams: Bigrams and trigrams were also considered to capture contextually relevant](#n-grams) (Page 7)  
   4.2. [Topic Modelling](#topic-modelling-2) (Page 7)  
   4.3. [Comparative Analysis of Topic Models](#comparative-analysis-of-topic-models) (Page 8)  
   4.3.1. [Triplet Matches (n=5): Groups consisting of one topic from each model (BERTopic,](#triplet-matches) (Page 8)  
   4.3.2. [Unique Topics (n=8): Topics from a single model that did not achieve a cosine](#unique-topics) (Page 9)  
   4.4. [Covariate Effect Estimation](#covariate-effect-estimation) (Page 10)  
5. [Results](#results) (Page 12)  
   5.1. [Comparative Analysis of Topic Models](#comparative-analysis-of-topic-models-2) (Page 12)  
   5.1.1. [BERTopic: Leverages pre-trained transformer models to generate context-aware](#bertopic) (Page 16)  
   5.1.2. [LDA: As a generative probabilistic model, LDA assumes topics are distributions over](#lda) (Page 17)  
   5.2. [Covariate Effect Estimation](#covariate-effect-estimation-2) (Page 17)  
6. [Conclusion](#conclusion) (Page 20)  
7. [Limitations and Future Work](#limitations-and-future-work) (Page 21)  
```
# PDF Summarization Pipeline

A Docker-based system for automatically generating table of contents from academic PDF papers using AI.

## ğŸš€ Quick Start

### 1. Build the Docker image

```bash
docker-compose build
```

### 2. Run the pipeline

```bash
docker-compose run --rm app python src/main.py
```

### 3. Add your PDFs

- Place PDF files in `data/input/` directory
- The system will automatically process all PDFs in this folder

### 4. Get results

- Processed results will appear in `data/output/`
- Each PDF gets its own folder with:
  - `table_of_contents.md` - Generated table of contents
  - `summary.json` - Structured data
  - `documents.json` - Raw document data

## ğŸ“ Project Structure

```
pdf_sum/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input/          # Place your PDFs here
â”‚   â””â”€â”€ output/         # Results appear here
â”œâ”€â”€ src/                # Source code
â”œâ”€â”€ docker-compose.yml  # Docker configuration
â””â”€â”€ requirements.txt    # Python dependencies
```

## âš™ï¸ Configuration

Create a `.env` file with your OpenAI API key:

```bash
OPENAI_API_KEY=your_api_key_here
```

## ğŸ“Š Output Example

Each processed PDF creates:

- **Markdown TOC**: Human-readable table of contents
- **JSON Summary**: Structured metadata and titles
- **Document Data**: Raw processing information


## ğŸ“ Requirements

- Docker & Docker Compose
- OpenAI API key
- Python 3.11+ (for local development)
